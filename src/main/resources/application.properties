# Server Configuration
server.port=8080

# Ollama Configuration
# This assumes Ollama is running locally on default port 11434
spring.ai.ollama.base-url=http://localhost:11434

# Chat Model Configuration (for generating answers)
spring.ai.ollama.chat.model=llama3.2
spring.ai.ollama.chat.options.temperature=0.2
spring.ai.ollama.chat.options.top-p=0.9

# Embedding Model Configuration (for creating vector embeddings)
# nomic-embed-text produces 768-dimensional embeddings automatically
spring.ai.ollama.embedding.model=nomic-embed-text

# Chroma DB Vector Store Configuration
spring.ai.vectorstore.chroma.client.host=localhost
spring.ai.vectorstore.chroma.client.port=8000
spring.ai.vectorstore.chroma.collection-name=canadian_tax_documents
spring.ai.vectorstore.chroma.initialize-schema=true

documents.path=./data/tax-documents

# Logging
logging.level.org.springframework.ai=DEBUG
logging.level.com.example=DEBUG